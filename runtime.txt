create a synthetic dataset of suffiecent rows size for Personalized azithromycin treatment rules for children with watery diarrhea using machine learning



with columns - patient characteristics, treatment given, duration , severity, microbiology/antibiotic resistance and others necesaary...

and we need to feature engineere these-
age groups, nutritional status(MUAC), travel history,previous infections, local antimicrobial resistence indices, and outcome would be patient specific benefit probabilities for azithromycin treatment 

also we need to clean missing values , encode categorical data(eg. dehydration grade), normalize continuous variables,and impute with clinicaaly appropriate method

so first give the code for to generate raw data and then the all cell combined together for noetbook to clean/feature_engineering/impute and make it training ready

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator, TransformerMixin

# --- Custom Transformers for Feature Engineering ---

class ClinicalFeatureEngineer(BaseEstimator, TransformerMixin):
    """
    Custom transformer to create domain-specific features 
    for pediatric diarrhea logic.
    """
    def fit(self, X, y=None):
        return self
    
    def transform(self, X):
        X = X.copy()
        
        # 1. Age Groups
        # <12mo: Infant, 12-59mo: Toddler, >60mo: Child
        bins = [0, 12, 60, 999]
        labels = ['Infant', 'Toddler', 'Child']
        X['age_group'] = pd.cut(X['age_months'], bins=bins, labels=labels)
        
        # 2. Nutritional Status (MUAC)
        # WHO Definitions: SAM < 11.5, MAM < 12.5, Normal >= 12.5
        # Note: MUAC must be imputed before this step ideally, or we handle NaNs here.
        # We will assume imputation happens prior to this call or logic handles it.
        conditions = [
            (X['muac_cm'] < 11.5),
            (X['muac_cm'] >= 11.5) & (X['muac_cm'] < 12.5),
            (X['muac_cm'] >= 12.5)
        ]
        choices = ['SAM', 'MAM', 'Normal']
        X['nutritional_status'] = np.select(conditions, choices, default='Unknown')
        
        # 3. AMR Risk Profile
        # Interaction between travel and previous antibiotics
        X['high_risk_resistance'] = (X['travel_history'] == 1) | (X['prev_abx_use'] == 1)
        
        # 4. Severity Index (Composite Score)
        # Normalize duration and stool freq into a rough score
        X['severity_index'] = (X['duration_symptoms_hours'] / 24) + (X['stool_frequency_daily'] / 5)
        
        return X

def clinically_appropriate_imputation(df):
    """
    Imputes missing values using logic derived from clinical correlations
    rather than simple means.
    """
    df_clean = df.copy()
    
    # Impute MUAC based on Age Group Median (Clinical Standard)
    # Older kids have larger arms naturally.
    df_clean['age_bin_temp'] = pd.cut(df_clean['age_months'], bins=[0, 12, 36, 60, 120])
    
    muac_medians = df_clean.groupby('age_bin_temp')['muac_cm'].transform('median')
    df_clean['muac_cm'] = df_clean['muac_cm'].fillna(muac_medians)
    
    # Impute Dehydration Grade with Mode (Most common presentation)
    dehyd_mode = df_clean['dehydration_grade'].mode()[0]
    df_clean['dehydration_grade'] = df_clean['dehydration_grade'].fillna(dehyd_mode)
    
    # Drop temp columns
    df_clean.drop(columns=['age_bin_temp'], inplace=True)
    
    return df_clean

# --- Main Execution ---

def run_processing_pipeline(filepath):
    print("Loading raw data...")
    df = pd.read_csv(filepath)
    
    # 1. Clinical Imputation (Manual Step before Pipeline)
    print("Running clinical imputation...")
    df_imputed = clinically_appropriate_imputation(df)
    
    # 2. Define Features and Target
    # Target: We want to predict the 'latent_benefit_prob' 
    # (The probability that Azithromycin specifically helps this patient)
    y = df_imputed['latent_benefit_prob']
    
    # Features to use
    feature_cols = [
        'age_months', 'gender', 'muac_cm', 'dehydration_grade', 
        'stool_frequency_daily', 'vomiting_history', 'fever',
        'duration_symptoms_hours', 'travel_history', 'prev_abx_use',
        'local_amr_index', 'etiology_confirmed' 
        # Note: We exclude 'treatment_given' and 'observed_recovery' 
        # because we are predicting the benefit *probability* pre-treatment.
    ]
    X = df_imputed[feature_cols]
    
    # 3. Split Data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # 4. Build Scikit-Learn Pipeline
    
    # Define column groups
    numeric_features = [
        'age_months', 'muac_cm', 'stool_frequency_daily', 
        'duration_symptoms_hours', 'local_amr_index'
    ]
    
    categorical_features = [
        'gender', 'vomiting_history', 'fever', 
        'travel_history', 'prev_abx_use', 'etiology_confirmed'
    ]
    
    ordinal_features = ['dehydration_grade']
    ordinal_order = [['None', 'Some', 'Severe']]
    
    # Preprocessors
    numeric_transformer = Pipeline(steps=[
        ('scaler', StandardScaler())
    ])
    
    categorical_transformer = Pipeline(steps=[
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])
    
    ordinal_transformer = Pipeline(steps=[
        ('ordinal', OrdinalEncoder(categories=ordinal_order))
    ])
    
    # Combine transformations
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features),
            ('ord', ordinal_transformer, ordinal_features)
        ])
    
    # Full Pipeline
    # Step 1: Feature Engineer (Create Age Groups, Nutritional Status)
    # Step 2: Transform/Encode/Normalize
    full_pipeline = Pipeline(steps=[
        ('feature_engineering', ClinicalFeatureEngineer()),
        ('preprocessor', preprocessor)
    ])
    
    print("Fitting pipeline...")
    # Note: We fit on Train, transform on Test
    X_train_processed = full_pipeline.fit_transform(X_train)
    X_test_processed = full_pipeline.transform(X_test)
    
    # Get feature names after OneHotEncoding for verification
    # This is a bit tricky with Pipelines, accessing the named step
    try:
        onehot_columns = full_pipeline.named_steps['preprocessor'].named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)
        print(f"\nSuccess! Processed Training Data Shape: {X_train_processed.shape}")
        print("Sample One-Hot Features:", onehot_columns[:5])
    except:
        print(f"\nSuccess! Processed Training Data Shape: {X_train_processed.shape}")

    return X_train_processed, y_train, X_test_processed, y_test

if __name__ == "__main__":
    # Ensure you have generated the data first
    try:
        X_train, y_train, X_test, y_test = run_processing_pipeline("raw_pediatric_diarrhea_data.csv")
        print("\nData is ready for Model Training (e.g., Random Forest, XGBoost).")
        print("Target Variable: Patient specific benefit probability (0.0 - 1.0)")
    except FileNotFoundError:
        print("Error: 'raw_pediatric_diarrhea_data.csv' not found. Run the generator script first.")